
########## Setting Up Experiment ######################

Putting log in GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=0.0001_batch_size=64_seq_len=35_hidden_size=1024_num_layers=2_dp_keep_prob=0.35_num_epochs=5_0
Using the GPU
Loading data from data
  vocabulary size: 10000

########## Running Main Loop ##########################

EPOCH 0 ------------------
step: 10	loss: 3548.367028236389	speed (wps):5954.028472022142
step: 51	loss: 16772.35263824463	speed (wps):6250.312944787167
step: 92	loss: 29995.9539270401	speed (wps):6288.159651446542
step: 133	loss: 43219.36869621277	speed (wps):6301.539565486372
step: 174	loss: 56442.98590660095	speed (wps):6309.693815859272
step: 215	loss: 69665.31617164612	speed (wps):6314.025528883382
step: 256	loss: 82888.14531326294	speed (wps):6317.8182952557945
step: 297	loss: 96109.60262775421	speed (wps):6320.059780867354
step: 338	loss: 109330.27894973755	speed (wps):6321.8175327189965
step: 379	loss: 122551.03731632233	speed (wps):6322.677719809707
epoch: 0	train ppl: 10038.695154889512	val ppl: 10000.495711831987	best val: 10000.495711831987	time (s) spent in epoch: 150.11390852928162

EPOCH 1 ------------------
step: 10	loss: 3546.860318183899	speed (wps):6186.055061511196
step: 51	loss: 16767.522253990173	speed (wps):6303.572409976085
step: 92	loss: 29986.74934387207	speed (wps):6315.651247194835
step: 133	loss: 43206.33068084717	speed (wps):6321.131020882544
step: 174	loss: 56425.74746131897	speed (wps):6324.107958240284
step: 215	loss: 69643.7388420105	speed (wps):6325.7759427739
step: 256	loss: 82861.30728244781	speed (wps):6327.731610941839
step: 297	loss: 96078.32871437073	speed (wps):6328.489786195721
step: 338	loss: 109295.3145980835	speed (wps):6329.011627883639
step: 379	loss: 122511.58307552338	speed (wps):6330.027324694331
epoch: 1	train ppl: 10008.983671861437	val ppl: 9970.361281512178	best val: 9970.361281512178	time (s) spent in epoch: 149.8803436756134

EPOCH 2 ------------------
step: 10	loss: 3545.688829421997	speed (wps):6192.941729175753
step: 51	loss: 16760.934085845947	speed (wps):6302.876039757905
step: 92	loss: 29975.926699638367	speed (wps):6315.427293850535
step: 133	loss: 43190.624113082886	speed (wps):6320.108245261401
step: 174	loss: 56405.597467422485	speed (wps):6323.983830278947
step: 215	loss: 69619.88913059235	speed (wps):6325.562777150446
step: 256	loss: 82833.96213054657	speed (wps):6326.1516417561825
step: 297	loss: 96046.91107273102	speed (wps):6327.024132203782
step: 338	loss: 109258.8855266571	speed (wps):6328.076480089085
step: 379	loss: 122471.03631973267	speed (wps):6328.320623663125
epoch: 2	train ppl: 9979.01266720927	val ppl: 9940.312915168492	best val: 9940.312915168492	time (s) spent in epoch: 149.89190196990967

EPOCH 3 ------------------
step: 10	loss: 3544.8692512512207	speed (wps):6192.886435460717
step: 51	loss: 16756.61950111389	speed (wps):6301.612914593163
step: 92	loss: 29967.281107902527	speed (wps):6313.307690767556
step: 133	loss: 43177.78700351715	speed (wps):6318.671917314083
step: 174	loss: 56388.49497318268	speed (wps):6321.676905460367
step: 215	loss: 69598.59041213989	speed (wps):6323.366633688467
step: 256	loss: 82807.88513183594	speed (wps):6324.3503006923875
step: 297	loss: 96016.87069892883	speed (wps):6325.570289925874
step: 338	loss: 109224.62853431702	speed (wps):6326.249070246057
step: 379	loss: 122432.43520259857	speed (wps):6327.036624150966
epoch: 3	train ppl: 9949.706769012564	val ppl: 9910.348019225772	best val: 9910.348019225772	time (s) spent in epoch: 149.96193933486938

EPOCH 4 ------------------
step: 10	loss: 3543.7066078186035	speed (wps):6197.252108927562
step: 51	loss: 16750.734219551086	speed (wps):6302.903361439454
step: 92	loss: 29956.61060333252	speed (wps):6316.557859027538
step: 133	loss: 43162.72948265076	speed (wps):6322.156095967841
step: 174	loss: 56368.48967552185	speed (wps):6325.243774115425
step: 215	loss: 69574.63432312012	speed (wps):6328.034752097289
step: 256	loss: 82779.13310527802	speed (wps):6329.746220181197
step: 297	loss: 95983.53882789612	speed (wps):6331.404834046566
step: 338	loss: 109187.48913288116	speed (wps):6333.459293353644
step: 379	loss: 122390.5938911438	speed (wps):6336.087967129486
epoch: 4	train ppl: 9918.534339780972	val ppl: 9880.476396538272	best val: 9880.476396538272	time (s) spent in epoch: 149.66674757003784

DONE

Saving learning curves to GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=0.0001_batch_size=64_seq_len=35_hidden_size=1024_num_layers=2_dp_keep_prob=0.35_num_epochs=5_0/learning_curves.npy
Set compute mode to DEFAULT for GPU 00000000:87:00.0.
All done.
