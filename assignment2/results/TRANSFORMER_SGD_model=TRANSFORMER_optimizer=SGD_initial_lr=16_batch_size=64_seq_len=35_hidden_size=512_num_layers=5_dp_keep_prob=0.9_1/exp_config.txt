batch_size    64
code_file    ptb-lm.py
data    data
debug    False
dp_keep_prob    0.9
emb_size    200
evaluate    False
hidden_size    512
initial_lr    16.0
model    TRANSFORMER
num_epochs    40
num_layers    5
optimizer    SGD
save_best    False
save_dir    ./results/TRANSFORMER_SGD_model=TRANSFORMER_optimizer=SGD_initial_lr=16_batch_size=64_seq_len=35_hidden_size=512_num_layers=5_dp_keep_prob=0.9
seed    1111
seq_len    35
