
########## Setting Up Experiment ######################

Putting log in ./results/GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=7_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_num_epochs=5
Using the GPU
Loading data from data
  vocabulary size: 10000

########## Running Main Loop ##########################

EPOCH 0 ------------------
step: 10	loss: 3370.7336568832397	speed (wps):1559.7470338566402
step: 142	loss: 36364.795405864716	speed (wps):1611.0906133521335
step: 274	loss: 67068.56081008911	speed (wps):1613.031895173298
step: 406	loss: 96586.22503519058	speed (wps):1614.0229912530922
step: 538	loss: 125658.12348365784	speed (wps):1614.3373995993616
step: 670	loss: 154345.96125602722	speed (wps):1615.2222990896162
step: 802	loss: 182332.8541636467	speed (wps):1616.0103489772584
step: 934	loss: 210137.21827745438	speed (wps):1617.1316019926003
step: 1066	loss: 237752.1540904045	speed (wps):1618.0191783786254
step: 1198	loss: 265033.3238697052	speed (wps):1618.7809534324983
epoch: 0	train ppl: 529.9794318589306	val ppl: 316.3373298668411	best val: 316.3373298668411	time (s) spent in epoch: 584.3861532211304

EPOCH 1 ------------------
step: 10	loss: 2313.771848678589	speed (wps):1594.8747735426955
step: 142	loss: 29089.095571041107	speed (wps):1621.7278008144635
step: 274	loss: 56157.787573337555	speed (wps):1623.2451063389285
step: 406	loss: 82808.62121343613	speed (wps):1623.8376642641447
step: 538	loss: 109494.71650838852	speed (wps):1623.9216648980837
step: 670	loss: 136091.85819864273	speed (wps):1624.9753941219112
step: 802	loss: 162197.42742300034	speed (wps):1626.101332854427
step: 934	loss: 188338.3529472351	speed (wps):1626.898885579122
step: 1066	loss: 214400.95268011093	speed (wps):1627.576431675346
step: 1198	loss: 240196.89141988754	speed (wps):1628.0063464011914
epoch: 1	train ppl: 301.7356937540342	val ppl: 238.5971170821606	best val: 238.5971170821606	time (s) spent in epoch: 581.0684518814087

EPOCH 2 ------------------
step: 10	loss: 2211.858551502228	speed (wps):1604.9503976280073
step: 142	loss: 27666.725850105286	speed (wps):1630.8445900693243
step: 274	loss: 53658.781962394714	speed (wps):1631.4000523488414
step: 406	loss: 79232.30583190918	speed (wps):1631.3318830542055
step: 538	loss: 104916.73419237137	speed (wps):1631.5420296425752
step: 670	loss: 130563.49817276001	speed (wps):1631.8620124433037
step: 802	loss: 155727.6746559143	speed (wps):1631.8856024833922
step: 934	loss: 180996.79718255997	speed (wps):1632.040313362621
step: 1066	loss: 206229.23555850983	speed (wps):1632.0716227872094
step: 1198	loss: 231140.5280661583	speed (wps):1632.0973967186303
epoch: 2	train ppl: 244.3284527850611	val ppl: 202.83921017911237	best val: 202.83921017911237	time (s) spent in epoch: 579.7844004631042

EPOCH 3 ------------------
step: 10	loss: 2148.9442443847656	speed (wps):1603.5389716462419
step: 142	loss: 26830.019433498383	speed (wps):1630.3158901888512
step: 274	loss: 52138.10458421707	speed (wps):1630.6682664918883
step: 406	loss: 76976.58122301102	speed (wps):1631.1108637436464
step: 538	loss: 101963.60658884048	speed (wps):1631.5042120380438
step: 670	loss: 126918.82380008698	speed (wps):1631.4856171680622
step: 802	loss: 151423.36499214172	speed (wps):1631.3671721935366
step: 934	loss: 176102.2920179367	speed (wps):1631.3739776545633
step: 1066	loss: 200771.6866827011	speed (wps):1631.3030887996356
step: 1198	loss: 225039.75675821304	speed (wps):1631.2861520280644
epoch: 3	train ppl: 211.7532603741309	val ppl: 183.8865661640047	best val: 183.8865661640047	time (s) spent in epoch: 580.0848979949951

EPOCH 4 ------------------
step: 10	loss: 2103.493354320526	speed (wps):1605.0863162515175
step: 142	loss: 26193.254776000977	speed (wps):1629.4204724390625
step: 274	loss: 50990.02091407776	speed (wps):1630.5934083219656
step: 406	loss: 75249.14201974869	speed (wps):1630.6731192433676
step: 538	loss: 99669.92136478424	speed (wps):1630.7872456976
step: 670	loss: 124083.3649110794	speed (wps):1630.9718412166255
step: 802	loss: 148076.252887249	speed (wps):1631.0893074572264
step: 934	loss: 172283.9549255371	speed (wps):1631.1073481732344
step: 1066	loss: 196474.59629297256	speed (wps):1631.1857347627001
step: 1198	loss: 220213.59671592712	speed (wps):1631.2049394107653
epoch: 4	train ppl: 188.9496557301142	val ppl: 168.82202387015826	best val: 168.82202387015826	time (s) spent in epoch: 580.0926284790039

DONE

Saving learning curves to ./results/GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=7_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_num_epochs=5/learning_curves.npy
Set compute mode to DEFAULT for GPU 00000000:08:00.0.
All done.
